import Head from "next/head";
import Image from "next/image";
import { Inter } from "@next/font/google";
import styles from "../styles/Home.module.css";
import * as faceapi from "face-api.js";
import { LabeledFaceDescriptors } from "face-api.js";
import { useEffect, useRef, useState } from "react";


export default function Home() {

  const imgRef = useRef(null);
  const canvasRef = useRef(null);

  // Detect faces and draw bos
  const handleImage = async () => {
    const detections = await faceapi
      //@ts-ignore
      .detectAllFaces(imgRef.current)
      .withFaceLandmarks()
      .withFaceDescriptors();
    //@ts-ignore
    canvasRef.current.innerHtml = faceapi.createCanvasFromMedia(imgRef.current);
    //@ts-ignore
    faceapi.matchDimensions(canvasRef.current, {
      width: 400,
      height: 300,
    });
    const resized = faceapi.resizeResults(detections, {
      width: 400,
      height: 300,
    });
    //@ts-ignore
    faceapi.draw.drawDetections(canvasRef.current, resized);
  };

  useEffect(() => {
    const loadModels = () => {
      Promise.all([
        faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
        faceapi.nets.faceLandmark68Net.loadFromUri("/models"),
        faceapi.nets.ssdMobilenetv1.loadFromUri("/models"),
      ])
        .then(handleImage)
        .catch((e) => console.log(e));
    };

    imgRef.current && loadModels();
  }, []);


  return (
    <>
      <Head>
        <title>Reconocimiento facial</title>
        <meta name="description" content="Generated by create next app" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="icon" href="" />
      </Head>
      <main style={{display: 'flex'}}>
        <img
          crossOrigin="anonymous"
          ref={imgRef}
          src="/1.jpg"
          width="400px"
          height="300px"
        />
        <canvas
          ref={canvasRef}
          style={{ position: "absolute", width: "400px", height: "300px" }}
        /> 
      </main>
    </>
  );
}
